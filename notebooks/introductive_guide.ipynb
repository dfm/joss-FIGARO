{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c84011b3",
   "metadata": {},
   "source": [
    "# FIGARO: an introductive guide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab8b9b1",
   "metadata": {},
   "source": [
    "This notebook shows how to use FIGARO, *Fast Inference for GW Astronomy, Research & Observations*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89180ee",
   "metadata": {},
   "source": [
    "## 1D probability density"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595edf42",
   "metadata": {},
   "source": [
    "We will start from a simple problem: inferring a 1D probability density given a set of samples drawn from it.\n",
    "Let's draw some samples from a Gaussian distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d689e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "mu = 30\n",
    "sigma = 3\n",
    "n_samps = 1000\n",
    "dist = norm(mu, sigma)\n",
    "\n",
    "samples = dist.rvs(n_samps)\n",
    "\n",
    "n, b, p = plt.hist(samples, bins = int(np.sqrt(len(samples))), histtype = 'step', density = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee189de4",
   "metadata": {},
   "source": [
    "FIGARO contains a class designed to infer probability densities given a set of samples.\n",
    "\n",
    "In order to instantiate the class, we need to specify the boundaries of the distribution.\n",
    "We will assume that our probability density is bounded between 10 and 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536cf3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from figaro.mixture import DPGMM\n",
    "\n",
    "x_min = 10\n",
    "x_max = 50\n",
    "\n",
    "mix = DPGMM([[x_min, x_max]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f33dc36",
   "metadata": {},
   "source": [
    "Please note that the boundaries must be passed as a 2D array. This is to ensure that the very same syntax holds for multidimensional distributions too.\n",
    "\n",
    "The idea is that the algorithm *learns* the shape of the probability density from the available samples, one at a time: every new sample adds a piece of information to the inference. Therefore, we need to pass the samples to our mixture one at a time in order to draw a single realisation of the Dirichlet Process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4872b593",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in tqdm(samples):\n",
    "    mix.add_new_point(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a2c5b4",
   "metadata": {},
   "source": [
    "Now that our mixture knows the shape of the distribution, we can build the probability density and initialise the mixture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ea6dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = mix.build_mixture()\n",
    "mix.initialise()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4555f9",
   "metadata": {},
   "source": [
    "Let's have a look at this reconstruction. `dist` contains the realisation we just drew, with some useful methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31a48d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[method_name for method_name in dir(rec)\n",
    "                  if callable(getattr(rec, method_name)) and not method_name.startswith('_')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3948db",
   "metadata": {},
   "source": [
    "`pdf` and `logpdf` take a 1D or 2D array and return, respectively, the probability and the log_probability of the inferred distribution, while `rvs` takes the number of desiderd samples and returns an array of draws.\n",
    "\n",
    "We now want to evaluate the probability density over the interval $[x_{min},x_{max}]$.   \n",
    "**WARNING: FIGARO uses a coordinate change that is singular at boundaries. Be careful not to evaluate the mixture on or outside the boundaries. This will result in infs or NaNs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41c44e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(x_min, x_max, 1002)[1:-1]\n",
    "p = rec.pdf(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66135ae",
   "metadata": {},
   "source": [
    "Let's compare the reconstruction with the samples and with the true distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec8d804",
   "metadata": {},
   "outputs": [],
   "source": [
    "n, b, t = plt.hist(samples, bins = int(np.sqrt(len(samples))), histtype = 'step', density = True, label = 'Samples')\n",
    "plt.plot(x, dist.pdf(x), color = 'red', lw = 0.7, label = 'Simulated')\n",
    "plt.plot(x, p, color = 'forestgreen', label = 'DPGMM')\n",
    "plt.legend(loc = 0, frameon = False)\n",
    "plt.grid(alpha = 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4ea4d8",
   "metadata": {},
   "source": [
    "This is a *single* realisation from the Dirichlet Process. In order to properly explore the distribution space, we need a set of draws: therefore we need to repeat the exercise of training the DPGMM for every new sample we want. \n",
    "\n",
    "The DPGMM class contains a method that is a wrapper for the `for` loop we wrote before, `DPGMM.density_from_samples()`, which returns a realisation from the DP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee305ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_draws = 100\n",
    "draws = []\n",
    "\n",
    "for _ in tqdm(range(n_draws)):\n",
    "    draws.append(mix.density_from_samples(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938571fa",
   "metadata": {},
   "source": [
    "Each call to `density_from_samples` reshuffles the samples.\n",
    "\n",
    "With the set of draws we have, we can compute median and credible regions for the probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83decf63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "probs = np.array([d.pdf(x) for d in draws])\n",
    "\n",
    "percentiles = [50, 5, 16, 84, 95]\n",
    "p = {}\n",
    "for perc in percentiles:\n",
    "    p[perc] = np.percentile(probs, perc, axis = 0)\n",
    "N = p[50].sum()*(x[1]-x[0])\n",
    "for perc in percentiles:\n",
    "    p[perc] = p[perc]/N\n",
    "\n",
    "n, b, t = plt.hist(samples, bins = int(np.sqrt(len(samples))), histtype = 'step', density = True, label = 'Samples')\n",
    "plt.fill_between(x, p[95], p[5], color = 'mediumturquoise', alpha = 0.5)\n",
    "plt.fill_between(x, p[84], p[16], color = 'darkturquoise', alpha = 0.5)\n",
    "plt.plot(x, dist.pdf(x), color = 'red', lw = 0.7, label = 'Simulated')\n",
    "plt.plot(x, p[50], color = 'steelblue', label = 'DPGMM')\n",
    "plt.legend(loc = 0, frameon = False)\n",
    "plt.grid(alpha = 0.6)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5633e9",
   "metadata": {},
   "source": [
    "The same plot can be obtained with the dedicated method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a0ab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from figaro.utils import plot_median_cr\n",
    "plot_median_cr(draws,\n",
    "               injected = dist.pdf,\n",
    "               samples  = samples,\n",
    "               save     = False,\n",
    "               show     = True,\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f666b9",
   "metadata": {},
   "source": [
    "The draws are uncorrelated from each other. The autocorrelation function is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7584dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from figaro.diagnostic import autocorrelation\n",
    "acf = autocorrelation(draws, bounds = [20, 40], save = False, show = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b50ea7",
   "metadata": {},
   "source": [
    "Let's look at the entropy to assess the convergence of the recovered distribution to the injected one.\\\n",
    "In order to do so, we need to draw a single realisation, saving it every time we add a new sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb66aff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix.initialise()\n",
    "updated_mixture = []\n",
    "\n",
    "for s in tqdm(samples):\n",
    "    mix.add_new_point(s)\n",
    "    updated_mixture.append(mix.build_mixture())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1756f0c8",
   "metadata": {},
   "source": [
    "Once we have all the history of how the single distribution has been generated, the FIGARO package comes with a method that produces entropy plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73508bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from figaro.diagnostic import entropy\n",
    "\n",
    "S = entropy(updated_mixture, show = True, save = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbb8115",
   "metadata": {},
   "source": [
    "It is also possible to compute an approximant of the entropy derivative to assess whether the distribution converged or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c181f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from figaro.diagnostic import plot_angular_coefficient\n",
    "\n",
    "ac = plot_angular_coefficient(S, show = True, save = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54a639f",
   "metadata": {},
   "source": [
    "When the number of accumulated samples is large enough to provide a good representation of the underlying distribution. the entropy reaches a plateau, and its derivative fluctuates around zero.\\\n",
    "Let's repeat the exercise with a larger number of samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32696d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samps = 5000\n",
    "samples = dist.rvs(n_samps)\n",
    "\n",
    "mix.initialise()\n",
    "updated_mixture = []\n",
    "\n",
    "for s in tqdm(samples):\n",
    "    mix.add_new_point(s)\n",
    "    updated_mixture.append(mix.build_mixture())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3468dae3",
   "metadata": {},
   "source": [
    "Let's look at the recovered distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3821a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_median_cr([updated_mixture[-1]],\n",
    "               injected = dist.pdf,\n",
    "               samples  = samples,\n",
    "               save     = False,\n",
    "               show     = True\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be8482c",
   "metadata": {},
   "source": [
    "Entropy and angular coefficient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffd1412",
   "metadata": {},
   "outputs": [],
   "source": [
    "S  = entropy(updated_mixture, show = True, save = False)\n",
    "ac = plot_angular_coefficient(S, show = True, save = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0150154",
   "metadata": {},
   "source": [
    "With this number of samples, the angular coefficient starts fluctuating around 0 after ~3000 samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04284a85",
   "metadata": {},
   "source": [
    "## Multidimensional probability density"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579fd16e",
   "metadata": {},
   "source": [
    "Multidimensional probability densities can be inferred using the same functions.\n",
    "\n",
    "Let's generate some data from a bivariate Gaussian distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d04114",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mn\n",
    "from corner import corner\n",
    "\n",
    "n_samps = 1000\n",
    "samples = mn(np.zeros(2), np.identity(2)).rvs(n_samps)\n",
    "\n",
    "c = corner(samples, color = 'coral', labels = ['$x$','$y$'], hist_kwargs={'density':True})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514ea3e7",
   "metadata": {},
   "source": [
    "The only difference with the previous case is that the mixture needs to be instantiated specifying the bounds for both dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ce7933",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min = -5\n",
    "x_max = 5\n",
    "y_min = -5\n",
    "y_max = 5\n",
    "\n",
    "mix_2d = DPGMM([[x_min, x_max],[y_min, y_max]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098d4b75",
   "metadata": {},
   "source": [
    "The inference runs exactly as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2982a526",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in tqdm(samples):\n",
    "    mix_2d.add_new_point(s)\n",
    "rec = mix_2d.build_mixture()\n",
    "mix_2d.initialise()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87d749c",
   "metadata": {},
   "source": [
    "Let's compare the initial samples with a set of samples drawn from the recovered distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02166b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_samples = rec.rvs(n_samps)\n",
    "\n",
    "\n",
    "c = corner(samples, color = 'coral', labels = ['$x$','$y$'], hist_kwargs={'density':True, 'label':'$\\mathrm{Samples}$'})\n",
    "c = corner(mix_samples, fig = c, color = 'dodgerblue', labels = ['$x$','$y$'], hist_kwargs={'density':True, 'label':'$\\mathrm{DPGMM}$'})\n",
    "l = plt.legend(loc = 0,frameon = False,fontsize = 15, bbox_to_anchor = (1-0.05, 1.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c60f55",
   "metadata": {},
   "source": [
    "Multiple draws:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4318e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_draws = 100\n",
    "draws = []\n",
    "\n",
    "for _ in tqdm(range(n_draws)):\n",
    "    draws.append(mix_2d.density_from_samples(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50c2168",
   "metadata": {},
   "source": [
    "## Hierarchical inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0000e0",
   "metadata": {},
   "source": [
    "Let's assume to have a set of samples $\\{x_1,\\ldots,x_k\\}$ from some probability density $F(x)$. Around each $x_i$, another process generated a set of samples $\\mathbf{y}_i = \\{y_1^i,\\ldots,y_n^i\\}$ according to some distribution $f_i(y|x_i)$.   \n",
    "To give a bit of context, $\\{x_1,\\ldots,x_k\\}$ could be the true masses of the black holes observed by LIGO and Virgo drawn from the mass function $F(x)$ and each $\\mathbf{y}_i$ could be the set of single-event primary mass posterior samples drawn from the posterior samples $f_i(y|x_i)$.\n",
    "\n",
    "In this section we'll see how to use FIGARO to infer $F(x)$ using $\\{\\mathbf{y}_1,\\ldots,\\mathbf{y}_k\\}$.\n",
    "In the following example, both $F(x)$ and $f_i(y|x_i)$ are Gaussian distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96a994e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 30\n",
    "sigma = 5\n",
    "n_evs = 1000\n",
    "n_post_samps = 100\n",
    "\n",
    "mass_function = norm(mu, sigma)\n",
    "true_masses = mass_function.rvs(n_evs)\n",
    "\n",
    "single_event_posteriors = [norm(norm(M, s).rvs(), s).rvs(n_post_samps) for M, s in zip(true_masses, np.random.uniform(1,3, size = len(true_masses)))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510a3b62",
   "metadata": {},
   "source": [
    "First of all, we need to reconstruct the $k$ probability densities $f_i$. For each $y_i$, we can use the DPGMM class.\n",
    "A proper analysis would require to draw multiple realisations for each posterior distribution. In this example, for the sake of time, we will draw only a handful of realisations for each event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3d87c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_draws = 10\n",
    "x_min = 1\n",
    "x_max = 70\n",
    "mix = DPGMM([[x_min, x_max]])\n",
    "\n",
    "posteriors = []\n",
    "for event in tqdm(single_event_posteriors, desc = 'Events'):\n",
    "    draws = []\n",
    "    for _ in range(n_draws):\n",
    "        draws.append(mix.density_from_samples(event))\n",
    "    posteriors.append(draws)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04617802",
   "metadata": {},
   "source": [
    "Once we have the single-event posterior reconstructions, we need the HDPGMM class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e93ee94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from figaro.mixture import HDPGMM\n",
    "hier_mix = HDPGMM([[x_min, x_max]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0686eff",
   "metadata": {},
   "source": [
    "The methods for this new class are the same we used before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0fb737",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_draws_hier = 100\n",
    "hier_draws = []\n",
    "\n",
    "for _ in tqdm(range(n_draws_hier)):\n",
    "    hier_draws.append(hier_mix.density_from_samples(posteriors))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57358804",
   "metadata": {},
   "source": [
    "In the same fashion, we can plot the recovered distribution using the dedicated method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b6a894",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_median_cr(hier_draws,\n",
    "               samples  = true_masses,\n",
    "               injected = mass_function.pdf,\n",
    "               show     = True,\n",
    "               hierarchical = True\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428fd0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41949b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
